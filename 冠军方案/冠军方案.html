<html>
<head>
  <title>Evernote Export</title>
  <basefont face="微软雅黑 Light" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/606060 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑 Light;
      font-size: 14pt;
    }
  </style>
</head>
<body>
<a name="16726"/>
<h1>冠军方案</h1>
<div>
<table bgcolor="#D4DDE5" border="0">
<tr><td><b>创建时间：</b></td><td><i>2021/11/8 14:31</i></td></tr>
<tr><td><b>更新时间：</b></td><td><i>2022/12/13 18:05</i></td></tr>
<tr><td><b>作者：</b></td><td><i>不理不理</i></td></tr>
</table>
</div>
<br/>

<div>
<span><div><div><br/></div><div><a href="https://www.kaggle.com/c/nfl-health-and-safety-helmet-assignment/discussion/284975" style="font-size: 18pt; font-weight: bold;">1st Place Solution</a></div><div>Thanks to organizers for this interesting challenge and congrats everyone who enjoyed it! It’s one of the most fun competitions that I’ve ever experienced. I especially appreciate Rob’s supports before and during competition. I believe he makes this competition such great thing.</div><div><br/></div><div>It’s really tough challenge. It requires various skills of detection, registration, optimization and tracking (and debugging). I guess many competitors build complicated pipelines, and struggled to debug it. I respect those who have completed this competition until the end. Congratulations!</div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">Overview of my solution</span></div><div>My pipeline consists of:</div><ul><li><div>Detector to find helmets.</div></li><li><div>Converter to project movies’ images to 2D map (bird’s eye view).</div></li><li><div>Classifier to classify players into 2(H/V) teams.</div></li><li><div>Registration of detected players on 2D map to provided tracking data.</div></li><li><div>Track detected bounding boxes and reassign players.</div></li></ul><div><br/></div><div>I guess the key difference between my solution and public notebooks is the mapping and registration modules, which gave me the score of approx. 0.8 only by helmets.csv though it works faster than 10 frames/sec on GPU.</div><div><br/></div><div>Let me explain each modules briefly.</div><div style="text-align: center;"><img src="冠军方案_files/fig_1.png" type="image/png" data-filename="fig_1.png" width="799"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">01. Helmet Detector</span></div><ul><li><div>2 stage detector to find helmets.</div></li><li><div>1st detector predicts the average helmets’ size and resize input images (higher resolution) based on it.</div></li><li><div>2nd detector detects helmets in high resolution images. I thought detecting fixed-size objects is easier than detecting objects of various sizes.</div></li></ul><div><br/></div><div>        我的理解：</div><ul><ul><li><div>该步生成的俯瞰视角坐标其坐标系是不确定的，即这一步主要用于确定画面中的头盔在俯瞰视角下的相对位置，而不是绝对坐标。</div></li><li><div>训练时：拿原始图像训练stage1模型，得到每张图中头盔的平均尺寸，然后将该图像缩放，使得stage1模型缩放后预测框的平均尺寸在25x25左右。进而拿缩放后的图像及标签训练stage2模型。</div></li><li><div>预测时：第一个检测器初步检测出图片中的头盔，依据这些头盔检测框的平均尺寸对原始图像进行缩放，然后将缩放后的图像输入第二个检测器，预测得到最终的检测框，最后将预测得到的检测框坐标缩放到原始图像的坐标系下。</div></li><li><div>为什么这么做：随着镜头的拉近拉远，运动员在画面里的身形会时大时小，因此检测器难以习得运动员头盔的具体尺寸</div></li></ul></ul><div style="text-align: center;"><img src="冠军方案_files/fig_2.png" type="image/png" data-filename="fig_2.png" width="805"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">02. Image to Map Converter</span></div><ul><li><div>CNN(U-Net base) to convert helmets’ bounding boxes in images to 2D map. It predicts 2D location(x and y) looking from camera location.</div></li><li><div>It outputs the global location from bottleneck and small residuals from decoder.</div></li><li><div>Attention by helmets bounding-boxes improves accuracy.</div></li></ul><div><br/></div><div>        我的理解：</div><ul><ul><li><div>训练时：已知图片中K个运动员对应的头盔真实框（标签）、总计22个运动员该时刻在场地上的绝对坐标、检测算法对于图片中N个头盔的预测框、以及Image2Map模型基于N个预测框生成的N个预测坐标，因而可以知道每个预测框对应哪个运动员（真实框与预测框进行基于IOU距离的匈牙利匹配），进而知道N个预测坐标与22个绝对坐标的一一<span style="font-weight: bold;">对应关系</span>（N&lt;22）。此时就可以迭代计算点集与点集的变换矩阵与变换误差，使用这个误差来更新Image2Map模型。</div></li><li><div>预测时：根据测试图片中的N个预测框用Image2Map模型生成N个预测坐标，同时将队伍信息转化为点的第三维坐标，然后与标签中的K个运动员坐标开始进行ICP点云配准。由于ICP非常依赖于初始的点云对齐（即每个预测坐标到底该与哪个真实坐标计算欧氏距离），因此每帧图像的点云配准会重复进行40+次的ICP，每次ICP配准之前都会对Image2Map模型生成的N个预测坐标整体进行随机的旋转、平移、缩放，然后与K个真实坐标进行迭代配准，最后计算本次ICP的拟合误差，取40次ICP拟合中误差较小的作为点云配准结果。</div></li></ul></ul><div style="text-align: center;"><img src="冠军方案_files/fig_3.png" type="image/png" data-filename="fig_3.png" width="775"/></div><div style="text-align: center;"><img src="冠军方案_files/BTcCZJg.png" type="image/png" data-filename="BTcCZJg.png" width="783"/></div><div style="text-align: center;"><br/></div><div style="text-align: center;"><img src="冠军方案_files/fig_3_3.png" type="image/png" data-filename="fig_3_3.png" width="785"/></div><div style="text-align: center;">（ Players' position in tracking data is the ground truth but the loss in this model is determined adaptively and actual target values(labels?) are not fixed in advance. ）</div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">03. Points to Points Registration</span></div><ul><li><div>Matching predicted players on 2D map to the provided tracking data.</div></li><li><div>ICP (Iterative Closest Points) based algorism. Iteratively solve the nearest search and normal equation to get 4 unknown parameters (xy translation, rotation and zoom ratio) by least squares fitting.</div></li><li><div>Pre/post-processing is applied to remove inappropriate predictions such as sideline players.</div></li></ul><div><br/></div><div>        我的理解：</div><ul><ul><li><div>使用之前帧的配准结果为初始值，添加L2损失限制移动</div></li><li><div>根据相机位置限制旋转角度</div></li><li><div>忽略远离其他球员的点</div></li></ul></ul><div style="text-align: center;"><img src="冠军方案_files/fig_4.png" type="image/png" data-filename="fig_4.png" width="867"/></div><div style="text-align: center;"><img src="冠军方案_files/fig_5.png" type="image/png" data-filename="fig_5.png" width="857"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">04. Team Classifier</span></div><ul><li><div>Team information is also important to improve the registration accuracy. X,Y location and team can be used in Points to Points Registration above.</div></li><li><div>CNN classifier predicts the similarity matrix to show each pair of players belongs to the same team or not.</div></li><li><div>Using arcface and pseudo-labeling improved the accuracy. Validation score is approx. 97%.</div></li></ul><div><br/></div><div>        我的理解：</div><ul><ul><li><div>队伍信息对提高配准的准确性很重要。作者使用CNN分类器对每个预测的头盔生成embedding，embedding之间两两计算相似度得到相似矩阵，相似矩阵的值表示每一对球员是否为同队。作者在这里使用了arcface和伪标签来提高准确性。</div></li></ul></ul><div style="text-align: center;"><img src="冠军方案_files/fig_6.png" type="image/png" data-filename="fig_6.png" width="817"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">05. Tracker</span></div><ul><li><div>Tracker accumulates the results of player assignment through all frames, and re-assign players to bounding boxes.</div></li><li><div>I applied simple IoU tracker because it’s fast and enough accurate.</div></li><li><div>Not only frequency but also tracking confidence and frame distance is used for reassignment. Assignment results far from the target frame should not be weighted.</div></li></ul><div><br/></div><div>        我的理解：</div><ul><ul><li><div>比如现在对第N帧的所有bbox进行目标修正，将第N帧的A个bbox与第N-1帧的B个bbox分别计算IOU与队伍相似度（拿Team Classifier计算得到的128维特征向量），得到A行B列的IOU距离矩阵和A行B列的队伍相似度矩阵，根据这两个矩阵和匈牙利匹配得到第N帧与第N-1帧各bbox之间的匹配结果<span style="font-size: unset; color: unset; font-family: unset;">，同理得到第N+1帧与第N帧各bbox的匹配结果，不过注意作者只对前后6帧进行目标追踪。现在考虑第N帧的bbox1，依据第N-1帧与当前帧的帧距离和IOU设定第N-1帧匹配结果的Weights，同理得到附近其他帧匹配结果的Weights，进而得到下图的橙色匹配矩阵，就可以使用匈牙利匹配修正当前帧的匹配结果。</span></div></li></ul></ul><div style="text-align: center;"><img src="冠军方案_files/fig_7.png" type="image/png" data-filename="fig_7.png" width="928"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">06. Ensemble</span></div><ul><li><div>WBF(Weighted Box Fusion) is applied in the reassignment phase in the tracker. It ensembles multi-frame and multi-model predictions.</div></li><li><div><span style="font-weight: bold;">Take the weighted average of the player-assignment matrix of each models, then choose the final assignment by Hungarian algorithm</span>. It works better than normal WBF which ensembles the results of bounding boxes and detection confidences only.</div></li><li><div>4 detectors’ ensemble for final submission.</div></li></ul><div><br/></div><div>        我的理解：</div><ul><ul><li><div>WBF集成了多帧多模型的预测结果，先得出每个模型在当前帧的球员分配矩阵（上图橙色矩阵），然后将各模型在当前帧的检测框进行WBF融合，得到各模型混合后的检测框，进而将各模型的球员分配矩阵根据WBF结果进行融合，最后通过匈牙利匹配选择最终分配结果</div></li></ul></ul><div style="text-align: center;"><img src="冠军方案_files/AAP5yKT.png" type="image/png" data-filename="AAP5yKT.png" width="905"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt; font-weight: bold;">Scores History</span></div><div style="text-align: center;"><img src="冠军方案_files/fig_9.png" type="image/png" data-filename="fig_9.png" width="894"/></div><div style="text-align: left;"><br/></div><div style="text-align: left;">        自己的理解：test_baseline_helmets.csv是官方提供的测试集头盔预测框。从图中可以看出，训练自己的检测模型对最终得分有明显的提升。图中的Training: Validation Split ratio指的是作者将原本全量的训练集拆分为训练集和本地验证集，划分比例仅影响Image2Map模型和Team模型。</div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 18pt;"><a href="https://www.kaggle.com/kmat2019/nfl-1stplace-inference" style="font-size: 18pt; font-weight: bold;">Inference code</a></span></div><div style="text-align: center;"><a href="冠军方案_files/main.py"><img src="冠军方案_files/69b823ae97806df58a397b4304c811b2.png" alt="main.py"></a></div><div style="text-align: center;">冠军方案的main文件，需要配合冠军放出的nfl2solution包才能使用</div><div style="text-align: center;"><br/></div><div style="text-align: center;"><a href="冠军方案_files/冠军代码注释版.zip"><img src="冠军方案_files/1d03d1b739c23e693cf6782a56bda714.png" alt="冠军代码注释版.zip"></a></div><div style="text-align: center;">将nfl2solution/model/路径下的5个py文件替换为上面压缩文件里的py文件</div><div style="text-align: center;"><br/></div><div style="text-align: center;"><a href="冠军方案_files/可视化.zip"><img src="冠军方案_files/bf649e09ae3b7ce65ddd1a593e5f3017.png" alt="可视化.zip"></a></div><div style="text-align: center;">冠军网络中部分特征图和预测结果的可视化及代码</div><div><br/></div></div><div><br/></div></span>
</div></body></html> 